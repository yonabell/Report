{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonabell/Report/blob/main/Reporting_final_python_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re"
      ],
      "metadata": {
        "id": "8R1fcuUjxILP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "VrzYh1MDxLPn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "c356b6ba-03ef-4903-87c1-6746583127c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6820d9da-6be3-490c-831e-d8bfbcdad6a6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6820d9da-6be3-490c-831e-d8bfbcdad6a6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2023_sample_data1.xlsx to 2023_sample_data1.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_previous_year = '2023_sample_data1.xlsx'"
      ],
      "metadata": {
        "id": "0L2i_J8fLxsH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file_path_current_year = 'path_to_input_folder/2024_sample_data.xlsx'\n",
        "# file_path_previous_year = 'path_to_input_folder/2023_sample_data.xlsx'\n",
        "# output_folder_path = 'path_to_output_folder/'"
      ],
      "metadata": {
        "id": "GKt-MzlhGYaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function for the following data cleaning steps\n",
        "def clean_data(file_path):\n",
        "    # Load the data with no predefined header\n",
        "    cpt_df = pd.read_excel(file_path, engine='openpyxl', header=4)\n",
        "\n",
        "    # Filtering rows and extracting only 'A' followed by nine digits\n",
        "    filtered_cpt_df = cpt_df[cpt_df['Unnamed: 0'].str.extract(r'(A\\d{9})', expand=False).notna()].copy()\n",
        "\n",
        "    # Extracting the ID\n",
        "    filtered_cpt_df['ID'] = filtered_cpt_df['Unnamed: 0'].str.extract(r'(A\\d{9})', expand=False)\n",
        "\n",
        "    # Reorder columns to place 'ID' next to 'Unnamed: 0'\n",
        "    cols = filtered_cpt_df.columns.tolist()\n",
        "    id_index = cols.index('ID')\n",
        "    cols = cols[:1] + [cols[id_index]] + cols[1:id_index] + cols[id_index + 1:]\n",
        "    filtered_cpt_df = filtered_cpt_df[cols]\n",
        "\n",
        "    # Drop 'Unnamed: 0' column\n",
        "    filtered_cpt_df = filtered_cpt_df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "    # Drop specific columns (1 to 7)\n",
        "    filtered_cpt_df = filtered_cpt_df.drop(filtered_cpt_df.columns[1:8], axis=1)\n",
        "\n",
        "    # Select every 7th column starting from the 8th column (index 7)\n",
        "    # Unnecessary column for the analysis with no data\n",
        "    column_names = filtered_cpt_df.columns.tolist()\n",
        "    columns_to_drop = column_names[7::7]\n",
        "\n",
        "    # Drop the selected columns from the DataFrame\n",
        "    filtered_cpt_df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "    return filtered_cpt_df"
      ],
      "metadata": {
        "id": "kcVm49man2pl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the clean_data function\n",
        "filtered_cpt_df1 = clean_data(file_path_previous_year) # file_path_current_year"
      ],
      "metadata": {
        "id": "iqy7t53MygMm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_suffix_with_months(df):\n",
        "    \"\"\"\n",
        "    This function replaces numerical suffixes in column names with corresponding month names\n",
        "    and replaces dots with spaces.\n",
        "\n",
        "    Args:\n",
        "    df (pd.DataFrame): The input DataFrame whose column names need to be updated.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: The DataFrame with updated column names.\n",
        "    \"\"\"\n",
        "    # Mapping of number suffixes to month names\n",
        "    month_map = {\n",
        "        '.1': ' Jan',\n",
        "        '.2': ' Feb',\n",
        "        '.3': ' Mar',\n",
        "        '.4': ' Apr',\n",
        "        '.5': ' May',\n",
        "        '.6': ' Jun',\n",
        "        '.7': ' Jul',\n",
        "        '.8': ' Aug',\n",
        "        '.9': ' Sep',\n",
        "        '.10': ' Oct',\n",
        "        '.11': ' Nov',\n",
        "        '.12': ' Dec'\n",
        "    }\n",
        "\n",
        "    # Replace dots with spaces and map suffixes at the end of column names to respective months\n",
        "    new_column_names = []\n",
        "    for column_name in df.columns:\n",
        "        new_column_name = column_name.replace('.', ' ')  # Replace dots with spaces\n",
        "        for suffix, month_name in month_map.items():\n",
        "            # Ensure we replace only if the suffix appears at the end of the column name\n",
        "            if new_column_name.endswith(suffix.replace('.', ' ')):\n",
        "                new_column_name = new_column_name.replace(suffix.replace('.', ' '), month_name)\n",
        "        new_column_names.append(new_column_name)\n",
        "\n",
        "    # Assign the new column names to the dataframe\n",
        "    df.columns = new_column_names\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "lNbIIHGvgqNT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_cpt_df1 = replace_suffix_with_months(filtered_cpt_df1)"
      ],
      "metadata": {
        "id": "T7s4b6Qdz7vg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rename_columns(filtered_cpt_df):\n",
        "    # Define the new column name mappings for replacements at the start of column names\n",
        "    new_column_names = {\n",
        "        'ID': 'BPID',\n",
        "        'Purch Volume': 'PurchVolume',\n",
        "        'S-Revenues': 'Revenue',\n",
        "        'Profit Margin I*': 'PMIStar',  # Handle the specific case for PMIStar first\n",
        "        'Profit Margin I': 'PMI',\n",
        "        'PM I % of Purchased Volume': 'PMIRate',\n",
        "        'PM I* % of Purchased Volume': 'PMIStarRate'\n",
        "    }\n",
        "\n",
        "    # Clean column names by collapsing multiple spaces into a single space\n",
        "    filtered_cpt_df.columns = [re.sub(r'\\s+', ' ', col) for col in filtered_cpt_df.columns]\n",
        "\n",
        "    # Iterate through the columns and apply the renaming based on the starting part of the name\n",
        "    updated_columns = []\n",
        "    for column in filtered_cpt_df.columns:\n",
        "        # Check if the column starts with any of the keys in new_column_names\n",
        "        for old_name, new_name in new_column_names.items():\n",
        "            if column.startswith(old_name):\n",
        "                # Replace the old part of the column name with the new one and keep the suffix (e.g., \"Jan\", \"Feb\")\n",
        "                new_column = column.replace(old_name, new_name, 1)\n",
        "                updated_columns.append(new_column)\n",
        "                break\n",
        "        else:\n",
        "            # If no match, keep the column name unchanged\n",
        "            updated_columns.append(column)\n",
        "\n",
        "    # Rename the columns in the dataframe\n",
        "    filtered_cpt_df.columns = updated_columns\n",
        "\n",
        "    return filtered_cpt_df"
      ],
      "metadata": {
        "id": "ZoQJLQ8912OW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_cpt_df1 = rename_columns(filtered_cpt_df1)"
      ],
      "metadata": {
        "id": "IwS9lHkEc0d5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function\n",
        "def add_blank_columns(input_df):\n",
        "    # Create a new DataFrame with the first column (assumed to be \"BPID\") as is\n",
        "    output_df = pd.DataFrame(input_df.iloc[:, 0])  # Keep the first column (e.g., \"BPID\") as is\n",
        "\n",
        "    # Counter to track insertion of new blank columns\n",
        "    counter = 0\n",
        "\n",
        "    # Loop through the columns of input_df starting from the second column\n",
        "    for i in range(1, len(input_df.columns)):\n",
        "        # Add the current column from input_df to output_df\n",
        "        output_df[input_df.columns[i]] = input_df.iloc[:, i]\n",
        "        counter += 1\n",
        "\n",
        "        # After every 6 columns, add a new blank column for readability\n",
        "        if counter % 6 == 0:\n",
        "            new_column_name = f\"Spacer_{i // 6}\"  # Temporary name for the blank column\n",
        "            output_df[new_column_name] = \"\"  # Add a blank column with a temporary header\n",
        "            counter = 0  # Reset the counter after adding the blank column\n",
        "\n",
        "    # Replace temporary spacer column names with five spaces as headers\n",
        "    output_df.columns = [\"     \" if \"Spacer\" in col else col for col in output_df.columns]\n",
        "\n",
        "    return output_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lFYac_kl9n2K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add blanck columns for readability\n",
        "final_cpt_df1 = add_blank_columns(filtered_cpt_df1)"
      ],
      "metadata": {
        "id": "QYioRT_ULGC4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_cpt_df1.columns"
      ],
      "metadata": {
        "id": "MPIPZEIsdA1e",
        "outputId": "43e7fe6b-ed3d-496a-c555-548c22bfb1d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['BPID', 'PurchVolume Jan', 'Revenue Jan', 'PMI Jan', 'PMIRate Jan',\n",
              "       'PMIStar Jan', 'PMIStarRate Jan', '     ', 'PurchVolume Feb',\n",
              "       'Revenue Feb', 'PMI Feb', 'PMIRate Feb', 'PMIStar Feb',\n",
              "       'PMIStarRate Feb', '     ', 'PurchVolume Mar', 'Revenue Mar', 'PMI Mar',\n",
              "       'PMIRate Mar', 'PMIStar Mar', 'PMIStarRate Mar', '     ',\n",
              "       'PurchVolume Apr', 'Revenue Apr', 'PMI Apr', 'PMIRate Apr',\n",
              "       'PMIStar Apr', 'PMIStarRate Apr', '     ', 'PurchVolume May',\n",
              "       'Revenue May', 'PMI May', 'PMIRate May', 'PMIStar May',\n",
              "       'PMIStarRate May', '     ', 'PurchVolume Jun', 'Revenue Jun', 'PMI Jun',\n",
              "       'PMIRate Jun', 'PMIStar Jun', 'PMIStarRate Jun', '     ',\n",
              "       'PurchVolume Jul', 'Revenue Jul', 'PMI Jul', 'PMIRate Jul',\n",
              "       'PMIStar Jul', 'PMIStarRate Jul', '     ', 'PurchVolume Aug',\n",
              "       'Revenue Aug', 'PMI Aug', 'PMIRate Aug', 'PMIStar Aug',\n",
              "       'PMIStarRate Aug', '     ', 'PurchVolume Sep', 'Revenue Sep', 'PMI Sep',\n",
              "       'PMIRate Sep', 'PMIStar Sep', 'PMIStarRate Sep', '     ',\n",
              "       'PurchVolume Oct', 'Revenue Oct', 'PMI Oct', 'PMIRate Oct',\n",
              "       'PMIStar Oct', 'PMIStarRate Oct', '     ', 'PurchVolume Nov',\n",
              "       'Revenue Nov', 'PMI Nov', 'PMIRate Nov', 'PMIStar Nov',\n",
              "       'PMIStarRate Nov', '     ', 'PurchVolume Dec', 'Revenue Dec', 'PMI Dec',\n",
              "       'PMIRate Dec', 'PMIStar Dec', 'PMIStarRate Dec', '     '],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame to an Excel file first\n",
        "final_cpt_df1.to_excel('2023_cpt_monthly_profitability.xlsx', index=False)  # Save DataFrame to Excel file\n",
        "\n",
        "# Download the Excel file\n",
        "files.download('2023_cpt_monthly_profitability.xlsx')"
      ],
      "metadata": {
        "id": "fRWort1PMjtB",
        "outputId": "c2b38f7b-1007-477c-8f80-cbb8e05e04e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_321f8cdc-5a8e-4969-b9e9-8202fc5757ab\", \"2023_cpt_monthly_profitability.xlsx\", 6184)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save 2023_cpt_monthly_profitability as an excel file\n",
        "final_cpt_df1.to_excel(f\"{output_folder_path}2023_cpt_monthly_profitability.xlsx\", index=False)\n",
        "print(\"Successfully saved 2023_cpt_monthly_profitability.xlsx\")"
      ],
      "metadata": {
        "id": "edmtfRzrU6O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "jY2uocJZJzIH",
        "outputId": "771d557c-332d-43cb-9656-255902aa01c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-468040e4-9350-440b-988c-de34c89749a0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-468040e4-9350-440b-988c-de34c89749a0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2024_sample_data1.xlsx to 2024_sample_data1.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_current_year = '2024_sample_data1.xlsx'"
      ],
      "metadata": {
        "id": "icpcaHhemRsG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the clean_data function\n",
        "filtered_cpt_df2 = clean_data(file_path_current_year)"
      ],
      "metadata": {
        "id": "nkbRNtJ4meh-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'filtered_cpt_df2' is your DataFrame\n",
        "filtered_cpt_df2 = replace_suffix_with_months(filtered_cpt_df2)"
      ],
      "metadata": {
        "id": "DEc-IhdCg-56"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_cpt_df2 = rename_columns(filtered_cpt_df2)"
      ],
      "metadata": {
        "id": "hJIJ1876ye1P"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add blanck columns for readability\n",
        "final_cpt_df2 = add_blank_columns(filtered_cpt_df2)"
      ],
      "metadata": {
        "id": "lb6EHfqiNUqn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame to an Excel file first\n",
        "final_cpt_df2.to_excel('2024_cpt_monthly_profitability.xlsx', index=False)  # Save DataFrame to Excel file\n",
        "\n",
        "# Download the Excel file\n",
        "files.download('2024_cpt_monthly_profitability.xlsx')"
      ],
      "metadata": {
        "id": "J8-dz2dnaQYZ",
        "outputId": "72d5a90f-81f1-4371-d7ac-1934572bb8c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c7a95450-a92b-4c62-87cc-1903abcf51a1\", \"2024_cpt_monthly_profitability.xlsx\", 6017)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save 2023_cpt_monthly_profitability as an excel file\n",
        "final_cpt_df2.to_excel(f\"{output_folder_path}2024_cpt_monthly_profitability.xlsx\", index=False)\n",
        "print(\"Successfully saved 2024_cpt_monthly_profitability.xlsx\")"
      ],
      "metadata": {
        "id": "2hIbTMDkW3QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to map month columns to their respective month-year combinations\n",
        "def map_month_columns(df, year):\n",
        "    month_mapping = {\n",
        "        'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04',\n",
        "        'May': '05', 'Jun': '06', 'Jul': '07', 'Aug': '08',\n",
        "        'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'\n",
        "    }\n",
        "\n",
        "    new_columns = []\n",
        "    for col in df.columns:\n",
        "        # Check if the column name contains one of the months\n",
        "        for month, num in month_mapping.items():\n",
        "            if month in col:\n",
        "                # If the column matches a month, append the respective year and month\n",
        "                # The first part of the column before the month is the metric name (e.g., 'PurchVolume')\n",
        "                metric = col.replace(f' {month}', '')  # Remove the month from the name\n",
        "                new_columns.append(f\"{metric} {num}.{year}\")\n",
        "                break\n",
        "        else:\n",
        "            # Keep non-month columns (e.g., 'BPID') unchanged\n",
        "            new_columns.append(col)\n",
        "\n",
        "    df.columns = new_columns\n",
        "    return df\n",
        "\n",
        "\n",
        "# Mapping columns for 2023\n",
        "filtered_cpt_df1_mapped = map_month_columns(filtered_cpt_df1, '2023')\n",
        "# Mapping columns for 2024\n",
        "filtered_cpt_df2_mapped = map_month_columns(filtered_cpt_df2, '2024')"
      ],
      "metadata": {
        "id": "ZE1HLRehjJMk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the two dataframes (filtered_cpt_df1_mapped and filtered_cpt_df2_mapped)\n",
        "# Skip the 'BPID' column in the second dataframe to avoid duplication\n",
        "combined_df = pd.concat([filtered_cpt_df1_mapped, filtered_cpt_df2_mapped.iloc[:, 1:]], axis=1)"
      ],
      "metadata": {
        "id": "FAruPZxzOyGe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to filter columns based on start and end months\n",
        "def filter_columns_by_period(df, start_month, end_month):\n",
        "    # Get the list of columns\n",
        "    columns = df.columns.tolist()\n",
        "\n",
        "    # Find all columns matching the start and end months\n",
        "    start_idx = None\n",
        "    end_idx = None\n",
        "\n",
        "    for i, col in enumerate(columns):\n",
        "        # Check for the first full set of columns that start with start_month\n",
        "        if start_month in col and 'PurchVolume' in col:\n",
        "            start_idx = i\n",
        "        # Check for the last full set of columns that include the end_month\n",
        "        if end_month in col and 'PMIStarRate' in col:\n",
        "            end_idx = i + 1  # Add 1 to include the end month columns in the slice\n",
        "\n",
        "    # Slice the dataframe columns within the start and end index\n",
        "    if start_idx is not None and end_idx is not None:\n",
        "        filtered_df = df.iloc[:, :1]  # Include the 'BPID' column\n",
        "        filtered_df = pd.concat([filtered_df, df.iloc[:, start_idx:end_idx]], axis=1)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid start or end month. Please check the month-year format.\")\n",
        "\n",
        "    return filtered_df\n",
        "\n",
        "# Example usage:\n",
        "start_month = '05.2023'  # Specify the start month (MM.YYYY format)\n",
        "end_month = '03.2024'    # Specify the end month (MM.YYYY format)\n",
        "\n",
        "# Filter the combined dataframe based on the given period\n",
        "filtered_combined_df = filter_columns_by_period(combined_df, start_month, end_month)"
      ],
      "metadata": {
        "id": "vuky3OL5Vtyd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "start_month = '10.2023'  # Specify the start month (MM.YYYY format)\n",
        "end_month = '09.2024'    # Specify the end month (MM.YYYY format)\n",
        "\n",
        "# Filter the combined dataframe based on the given period\n",
        "filtered_combined_df = filter_columns_by_period(combined_df, start_month, end_month)"
      ],
      "metadata": {
        "id": "UXOLvae1WEQY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adjusted_factor = 0.0018"
      ],
      "metadata": {
        "id": "fZQtO5pHgphi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_combined_cpt_df = add_blank_columns(filtered_combined_df)"
      ],
      "metadata": {
        "id": "y3uoRGcWf2-2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new DataFrame with modified column names\n",
        "output_cpt_df = final_combined_cpt_df.copy()\n",
        "output_cpt_df.columns = [re.sub(r'\\s\\d{2}\\.\\d{4}$', '', col) for col in output_cpt_df.columns]\n",
        "#output_cpt_df.columns = [re.sub(r'\\.\\d{2}\\.\\d{4}$', '', col) if col != 'BPID' else col for col in output_cpt_df.columns]\n",
        "\n",
        "# Display the result to verify\n",
        "print(output_cpt_df.head())"
      ],
      "metadata": {
        "id": "lxxhNMNRSwTV",
        "outputId": "955667d6-aafb-49e2-c76e-5ddf93e30462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         BPID  PurchVolume Revenue    PMI  PMIRate  PMIStar  PMIStarRate  \\\n",
            "5  A987654321         65.0    34.0   34.0   9.8384     45.0        2.033   \n",
            "8  A123456789        543.0   725.0  643.0  15.7322    542.0        2.519   \n",
            "\n",
            "          PurchVolume Revenue  ...  PMIStar  PMIStarRate         PurchVolume  \\\n",
            "5                65.0    34.0  ...     45.0        2.033                65.0   \n",
            "8               543.0   725.0  ...    542.0        2.519               543.0   \n",
            "\n",
            "  Revenue    PMI  PMIRate  PMIStar  PMIStarRate         \n",
            "5    34.0   34.0   9.8384     45.0        2.033         \n",
            "8   725.0  643.0  15.7322    542.0        2.519         \n",
            "\n",
            "[2 rows x 85 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame\n",
        "df = pd.DataFrame(output_cpt_df)\n",
        "\n",
        "# Extract the name of the first column to group by it (e.g., 'BPID')\n",
        "group_column = df.columns[0]\n",
        "\n",
        "# Define metrics and their patterns to sum across columns\n",
        "metrics = ['PurchVolume', 'Revenue', 'PMI', 'PMIRate', 'PMIStar', 'PMIStarRate']\n",
        "\n",
        "# Initialize a dictionary to store aggregated results\n",
        "aggregated_results = {group_column: df[group_column].unique()}\n",
        "\n",
        "# For each metric, find matching columns, sum them, and add to results\n",
        "for metric in metrics:\n",
        "    metric_columns = [col for col in df.columns if re.match(fr'^{metric}', col)]\n",
        "    aggregated_results[metric] = df[metric_columns].sum(axis=1)\n",
        "\n",
        "# Create the final aggregated DataFrame\n",
        "aggregated_df = pd.DataFrame(aggregated_results)\n",
        "\n",
        "# Group by BPID and take the sum to get a single row per BPID with aggregated metrics\n",
        "aggregated_df = aggregated_df.groupby(group_column).sum().reset_index()\n",
        "\n",
        "print(aggregated_df)"
      ],
      "metadata": {
        "id": "F5dn531oVeBq",
        "outputId": "1a4804f7-9f31-44d6-ae94-94e9b1f1fceb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         BPID  PurchVolume    Revenue            PMI   PMIRate        PMIStar  \\\n",
            "0  A123456789     187812.0   130188.0  207575.956796  2747.544  118104.412796   \n",
            "1  A987654321      68196.0  1054164.0  115384.911875  1718.448   17690.463875   \n",
            "\n",
            "   PMIStarRate  \n",
            "0   372.412796  \n",
            "1   290.463875  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adjusted_factor = 0.0018"
      ],
      "metadata": {
        "id": "JlSwzXbSeE_E"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the PMIStarRate column\n",
        "aggregated_df['PMIStarRate'] = aggregated_df['PMIStarRate'] - (adjusted_factor * aggregated_df['PurchVolume'])\n",
        "\n",
        "# Display the modified DataFrame\n",
        "print(aggregated_df)\n"
      ],
      "metadata": {
        "id": "wbVbar5neBIP",
        "outputId": "42d8e9d0-4fa0-4476-d3b3-737a6c41b186",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         BPID  PurchVolume    Revenue            PMI   PMIRate        PMIStar  \\\n",
            "0  A123456789     187812.0   130188.0  207575.956796  2747.544  118104.412796   \n",
            "1  A987654321      68196.0  1054164.0  115384.911875  1718.448   17690.463875   \n",
            "\n",
            "   PMIStarRate  \n",
            "0    34.351196  \n",
            "1   167.711075  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final combined (2023 and 2024) output\n",
        "output_cpt_df.to_excel(f\"{output_folder_path}Combined_cpt_monthly_profitability.xlsx\", index=False)\n",
        "print(\"Successfully saved Combined_cpt_monthly_profitability.xlsx\")"
      ],
      "metadata": {
        "id": "YsJu9BAjV8hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the current and previous year dynamically\n",
        "current_year = datetime.now().year\n",
        "previous_year = current_year - 1\n",
        "\n",
        "# Define input folder and output folder paths\n",
        "input_folder_path = 'path_to_your_input/'\n",
        "output_folder_path = 'path_to_output_folder/'\n",
        "\n",
        "# Assign file paths dynamically\n",
        "current_year_file_path = os.path.join(input_folder_path, f'{current_year}_sample_data.xlsx')\n",
        "previous_year_file_path = os.path.join(input_folder_path, f'{previous_year}_sample_data.xlsx')\n",
        "\n",
        "# Saving aggregated data for the current year\n",
        "aggregated_df1.to_excel(os.path.join(output_folder_path, f'{current_year}_aggregated.xlsx'), index=False)\n",
        "\n",
        "# Saving aggregated data for the previous year\n",
        "aggregated_df2.to_excel(os.path.join(output_folder_path, f'{previous_year}_aggregated.xlsx'), index=False)\n"
      ],
      "metadata": {
        "id": "2WYsHemNOkzy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colaboratory",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}